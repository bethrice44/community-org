# pywatts & sktime tech discussion, 6 May 2022

###### tags: `sktime`, `pywatts`

**:calendar:** 2022, May 6

## :wave: Attendees

- [name=Stefan Meisenbacher]
- [name=Franz Kiraly]
- [name=Benedikt Heidrich]
- [name=Kaleb Phipps]




## Actions from last meeting

action all (individual or group-wise)
design proposals for `__call__` dunder and associated classes
try send by May 5 EoB, pre-read for May 6

action FK: open issue on sktime to collect designs (but don't put design directly in issue before May 5)


## actions for next time

action FK: open issue on sktime to collect designs (but don't put design directly in issue before May 5)

review below, possibly feedback & note down

prepare thoughts for planning meeting May 13 - what should tickets be; design/requirements items; implementation items (mock-up, user journey?)


# pywatts ideas

## API Ideas:
The call dunder for each API needs as arguments:
* inputs (previous modules) -> List, Dict, or kwargs
* targets (previous moduls) -> List, Dict, or kwargs
* Execution Control parameter: Should the step be trained or only transformed or always trained. Which transform method should be executed (inverse, normal, probabilistic)
* Online Based Features as refit conditions to determine when a module should be refitted. Additionally, online learning/execution based parameters would be lag, batch, etc.
* Callbacks: Possibility to work directly on the output of a module. Could also be realised by a special type of module instead of callbacks.


##  Graphpipeline without seeing Pipeline Objects
Based on the idea of Franz to replace the StepInformation: 

```python=
interpolated = LinearInterpolation()(x=Column("bar"))
calendar = CalendarExtraction()(x=interpolated)
scaler = StandardScaler()
scaled = SKLearnWrapper(scaler)(x=interpolated)
outliers = SKLearnWrapper(LocalOutlierFactor())(x=scaled, calendar=calendar)


regressor1 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)
regressor2 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)

regressor1.train(data)
regressor2.train(data)

collected_results = Collector()(x1=regressor1, x2=regressor2)
colelcted_results.train()


outliers.train(data)
```

### Idea:
Try to construct a pipeline objects without the need of explicitly creating a pipeline. I.e., the pipeline object returned by the call dunder describes the pipeline up to the module added by the specifica call dunder. To realise such an API the call dunder has to:
* return a Pipeline Object or something similar. I.e. the StepInformation has to be enhanced. And it must be possible to call train, test, etc directly on the new StepInformation.




### Possible Challenges:
* How are global parameters set?
  * FileManager
  * Online/Batch Execution Flag, ...
* Each module or returned Pipeline Object has to track all needed inputs and the corresponding name of the column in the dataset. I.e., each returned PipelineObjects needs pointers to it's predessors and the input steps.
* Check if the output of the predecessor fits to the input of the added pipeline. E.g., if we have different modules/estimators like motif discovery, forecasting etc. their outputs differs. If it is allowed to combine different ones in one pipeline, we should check this before the execution of the pipeline.
* Need to specify the input columns of the first module/estimator (`x=Column("bar")`)
* Where should storage paths be determined (Currently in the initialisation of the pipeline.)
* Are Pipelines with multiple output possible? Probably only with Dummy (`Collector()`) which collects multiple modules/estimators


### Advantages:
* The user has not to care about creating a Pipeline. Because *Everything is a Pipeline*. Clean way to construct pipelines.

## Alternative: Extend Existing API

The current API works. However, a new can prettify it and the API has to be enhanced. The `StepInformation` is kept.


```python=
pre_processing_pipeline = Pipeline()
interpolated = LinearInterpolation()(x=pipeline("bar"))
calendar = CalendarExtraction()(x=interpolated)
scaler = StandardScaler()
scaled = SKLearnWrapper(scaler)(x=interpolated)
outliers = SKLearnWrapper(LocalOutlierFactor())(x=scaled, calendar=calendar)

estimator_pipeline = Pipeline()
regressor1 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)
regressor2 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)


estimator_pipeline.train(data)

# can be applied elsewhere
pre_processing_pipeline.to_folder(path...)
```

### Challenges:
* Check if the output of the predecessor fits to the input of the added pipeline. E.g., if we have different modules/estimators like motif discovery, forecasting etc. their outputs differs. If it is allowed to combine different ones in one pipeline, we should check this before the execution of the pipeline.

### Advantage
* Multiple last modules/estimators are possible without collector steps or something similar

## Alternative: Full Keras API Style
Define Pipeline after the describing how the different steps are connected.


```python=
interpolated = LinearInterpolation()(x=Column("bar"))
calendar = CalendarExtraction()(x=interpolated)
scaler = StandardScaler()
scaled = SKLearnWrapper(scaler)(x=interpolated)
outliers = SKLearnWrapper(LocalOutlierFactor())(x=scaled, calendar=calendar)


regressor1 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)
regressor2 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)


# Full Keras Style
pipeline = Pipeline(inputs=[interpolated], targets=[regressor1, regressor2, outlier])

pipeline.train(data)
```

### Challenges:
* Check if the output of the predecessor fits to the input of the added pipeline. E.g., if we have different modules/estimators like motif discovery, forecasting etc. their outputs differs. If it is allowed to combine different ones in one pipeline, we should check this before the execution of the pipeline.

### Drawback:
* If a last step is deleted the user has to adapt the line where the pipeline is created. Coding errors may arise here.

## Alternative: Pipeline without Step Information

Similar like the current API but instead of step information an estimator or Graphpipeline is returned.

```python=
pipeline = Pipeline()
interpolated = LinearInterpolation()(x=pipeline("bar"))
calendar = CalendarExtraction()(x=interpolated)
scaler = StandardScaler()
scaled = SKLearnWrapper(scaler)(x=interpolated)
outliers = SKLearnWrapper(LocalOutlierFactor())(x=scaled, calendar=calendar)


regressor1 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)
regressor2 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)


pipeline.train(data)


# Now this is possible
regressor1.transform(data)
```

### Challenges:
* Check if the output of the predecessor fits to the input of the added pipeline. E.g., if we have different modules/estimators like motif discovery, forecasting etc. their outputs differs. If it is allowed to combine different ones in one pipeline, we should check this before the execution of the pipeline.
* How are global parameters set for e.g. `regressor1.transform(data)`
  * FileManager
  * Online/Batch Execution Flag, ...
* Each module or returned Pipeline Object has to track all needed inputs and the corresponding name of the column in the dataset. I.e., each returned PipelineObjects needs pointers to it's predessors and the input steps.
* Where should storage paths be determined (Currently in the initialisation of the pipeline.) for `regressor1.transform(data)`


### Advantages:
* There is no step information and each object in the pipeline is fittable, i.e. we can directly call fit or transform for a regressor in the pipeline (as shown in example)



# FK/sktime ideas


## General design points for FK design suggestion

* finds general `__call__` idea very nice
* wrapping `StepFactory` directly seems counterintuitive UX, since it has signature `estimator(estimator, stuff) -> something_strange`
* similar `sktime` dunders return estimators, so moving to `estimator(estimator, stuff) -> estimator`
* based on graph pipeline similar to mlr3
* `StepFactory` retained as-is, maybe some minor back/forth refactor
* using `sktime` base classes for estimators/modules

## challenges

`estimator(estimator, stuff) -> estimator` not entirely clear

return could be polymorphic, is it transformer, forecaster, classifier? Depending on that, user may expect different methods

there may not be a single "end node"

## new object: `GraphPipeline`

* estimator-like interface for `StepInformation`
* can be constructed with `StepInformation`, or using `StepFactory`

Does two things:
* wraps `StepInformation` and "add one more layer" operation
* provides estimator interface on top of `StepInformation`

How: wraps and delegates to `GraphPipelineForecaster`, `GraphPipelineClassifier` etc, if output type is one of these

Example usage (direct, internal):

```python

pipe = GraphPipeline(my_stepinformation)

# my_stepinformation happens to define a forecaster
pipe.scitype
> forecaster

# now we can use it as forecaster
pipe.fit(y=airline, fh=[1,2,3])
pipe.predict()
pipe.predict_interval()
# and so on, forecaster specific methods

pipe.get_params()
# should give parameters of all the components, and components
# should this also give access to a graph structure abstraction?
```

problem: multiple end nodes??

pipe.scitype
> {"end_1": "forecaster", "end_2": "transformer"}

dictionary of end nodes?

how to deal with different parameters?

## `GraphPipeline` is returned by `__call__` dunder

some changes:

* would move "previous steps" to the front of the input, can collect in a dict or list, or in single `GraphPipeline`
* simple wrap/unwrap via `GraphPipeline` of current `StepInformation`



```python

class BaseForecaster(BaseObject):
    
    # etc

    def __call__(self, pipe: GraphPipeline, stuff):
        
        return GraphPipeline(
            StepFactory().create_step(
                self,
                steps,
                stuff
            )
        )
```


## Possible implementation of `GraphPipeline` types: delegation

```python

class GraphPipeline(BaseObject):

    def __init__(self, steps, stuff):

        scitype = self._infer_scitype(steps)
        self._scitype = scitype

        if scitype == "forecaster":
            self.estimator = GraphPipelineForecaster(steps, stuff)
        elif etc


    @property
    def scitype(self):
        return self._scitype

    def _infer_scitype(self, steps):
        # infers based on graph/type structure

    # example method
    def predict(self, **kwargs):

        if _has_predict(self.scitype):
            return self.estimator.predict(**kwargs)
        else:
            raise TypeError(
                f"GraphPipeline has scitype {self.scitype}"
                f"and hence no predict method"
            )
```


## Possible implementation B of `GraphPipeline` types: dispatch

```python

def make_graph_pipeline(steps, stuff):

    scitype = self._infer_scitype(steps)

    if scitype == "forecaster":
        return GraphPipelineForecaster(steps, stuff)
    elif etc
```

then in the `__call__` dunder

```python

class BaseForecaster(BaseObject):
    
    # etc

    def __call__(self, pipe: GraphPipeline, stuff):
        
        return make_graph_pipeline(
            StepFactory().create_step(
                self,
                steps,
                stuff
            )
        )
```

where `GraphPipeline` is an intermediate base or mixin class for `GraphPipelineForecaster`, `GraphPipelineClassifier`, etc

## questions

* How do we avoid the Banana/Gorilla/Jungle problem? Too many classes attached to dunders?
Can we factor out parser concern from base classes?

* what about step informations that include things like plotting etc? How does `GraphPipeline` behave in those cases?



# Notes

interesting example:

scaler S
feature extractor X
forecaster F

pipeline is as follows:

data -> S
S -> X,
X, S -> F

what happns in `predict`?

i.e., where does output of `F.predict()` go next?
Which `inverse_transform`s are called, with what input, in what sequence?

Probably only want `S.inverse_transform` to be called and `X` ignored?

Because if `X.inverse_transform` is also called, then what doese `S.inverse_transform` get? Coudl get output from `X.inverse_transform`, or output from `F.predict()`, *but* in general the column union etc will not work, and the two outputs will not be identical!

FK: have seen this problem also in `inverse_transform` of `FeatureUnion`.
I think it is the same problem, e.g., what should `inverse_transform` of `FeatureUnion` be? Unclear.

does it mean the inverse always needs to follow some linear path, even if the "forward" is a genuine graph?

pywatts solution: manually specify what is done in fit and in transform/predict, same estimator (by reference!) is added multiple times but gets a flag when it is called
